{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The objectives of the lab\n",
    "This practical session aims at showing how to build a simple recommender system on the movie lens dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exercise 1 (SVD and weighted SVD on MovieLens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The MovieLens Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) What is the Movie Lens data set? You can look at https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens dataset is a collection of movie ratings and user information, widely used for building and evaluating recommender systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Why is it preferable to begin with the MovieLens 100K Dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens 100K Dataset is a smaller version of the dataset, making it easier to work with initially for experimentation and learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Download the MovieLens100k dataset that is the ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2          3\n",
       "0  196  242  3  881250949\n",
       "1  186  302  3  891717742\n",
       "2   22  377  1  878887116\n",
       "3  244   51  2  880606923\n",
       "4  166  346  1  886397596"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define data directory and shape\n",
    "data_dir = \"ml-100k/\"\n",
    "data_shape = (943, 1682)\n",
    "\n",
    "# Load the MovieLens 100K dataset into a DataFrame\n",
    "df = pd.read_csv(data_dir + \"u.data\", sep=\"\\t\", header=None)\n",
    "values = df.values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   0       100000 non-null  int64\n",
      " 1   1       100000 non-null  int64\n",
      " 2   2       100000 non-null  int64\n",
      " 3   3       100000 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) What are the differences between the table df and the rating matrix M?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'df' is a DataFrame containing raw user-movie-rating data, while 'M' will be a sparse matrix representing the user-movie rating matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Use scipy sparse type to obtain a (sparse) rating matrix M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/k7ywl20s5t90qkylbxspkw080000gn/T/ipykernel_88704/116358778.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  M = sp.csr_matrix((values[:, 2], (values[:, 0], values[:, 1])), dtype=np.float, shape=data_shape)\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "# Suppose you have loaded your data into 'values' and calculated 'data_shape'\n",
    "\n",
    "# Find the maximum user and movie IDs\n",
    "num_users = np.max(values[:, 0]) + 1  # Adding 1 to account for 0-based indexing\n",
    "num_movies = np.max(values[:, 1]) + 1  # Adding 1 to account for 0-based indexing\n",
    "\n",
    "# Create a new 'data_shape' based on the number of users and movies\n",
    "data_shape = (num_users, num_movies)\n",
    "\n",
    "# Create a CSR matrix with the corrected data_shape\n",
    "M = sp.csr_matrix((values[:, 2], (values[:, 0], values[:, 1])), dtype=np.float, shape=data_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) How is coded the missing data in the sparse matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data in the sparse matrix is represented as zero values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Split the data into two matrices. Use 90% for training and 10 % for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the percentage for training data\n",
    "train_percentage = 0.9\n",
    "\n",
    "# Get the number of rows in your data (number of ratings)\n",
    "num_ratings = len(values)\n",
    "\n",
    "# Calculate the number of samples for training based on the percentage\n",
    "num_train_samples = int(train_percentage * num_ratings)\n",
    "\n",
    "# Create an array of indices to shuffle your data\n",
    "indices = np.arange(num_ratings)\n",
    "\n",
    "# Shuffle the indices randomly\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split the shuffled indices into training and testing indices\n",
    "train_indices = indices[:num_train_samples]\n",
    "test_indices = indices[num_train_samples:]\n",
    "\n",
    "# Use the indices to split the data into training and testing sets\n",
    "training_data = values[train_indices]\n",
    "testing_data = values[test_indices]\n",
    "# Now, 'training_data' and 'testing_data' contain the training and testing portions of your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Compute the global mean of the ratings given by the users to the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.52986"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_mean = M.sum() / M.nnz\n",
    "global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Center the data and compute the test error when predicting missing values by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Centering the data by subtracting the global mean\u001b[39;00m\n\u001b[1;32m      2\u001b[0m centered_data \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 3\u001b[0m centered_data[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m global_mean\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Extract the test data (assuming 'testing_data' contains your testing data)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m test_users \u001b[38;5;241m=\u001b[39m testing_data[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Centering the data by subtracting the global mean\n",
    "centered_data = values.copy()\n",
    "centered_data[:, 2] -= global_mean\n",
    "\n",
    "# Extract the test data (assuming 'testing_data' contains your testing data)\n",
    "test_users = testing_data[:, 0].astype(int)\n",
    "test_movies = testing_data[:, 1].astype(int)\n",
    "test_ratings = testing_data[:, 2]\n",
    "\n",
    "# Predict missing values using the global mean\n",
    "predicted_ratings = np.full(len(test_ratings), global_mean)\n",
    "\n",
    "# Calculate the mean squared error (MSE) for the predictions\n",
    "mse = mean_squared_error(test_ratings, predicted_ratings)\n",
    "\n",
    "# Print the MSE as the test error\n",
    "print(f\"Test Error (MSE) when predicting missing values by the mean: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Recommending using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Compute the 20 first factors of the SVD of the centered training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Predict the missing test values using the SVD with an increasing number of component (up to 20).\n",
    "Evaluate the performance of this approach on the test matrix and plot the resulting performance\n",
    "as a function of the number of factors of the SVD used to perform the reconstruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
